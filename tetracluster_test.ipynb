{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "class Box:\n",
    "    def __init__(self, data_matrix, initial_i):\n",
    "        self.dim = len(data_matrix.shape)\n",
    "        self.data = data_matrix\n",
    "        self.lambda_0 = data_matrix.mean()\n",
    "        self.data_shift = self.data - self.lambda_0 \n",
    "        self.initialize_sets(initial_i)\n",
    "    \n",
    "    def initialize_sets(self, initial_i):\n",
    "        self.sets = [set() for i in range(self.dim)]\n",
    "        self.sets[0].add(initial_i)\n",
    "        idx = []\n",
    "        idx.append([initial_i])\n",
    "        for i in range(1, self.dim):\n",
    "            idx.append(slice(None))\n",
    "        non_zero_args = np.nonzero(self.data[idx])\n",
    "        for dim in range(1, self.dim):\n",
    "            self.sets[dim] = set(non_zero_args[dim].tolist())\n",
    "    \n",
    "    def update(self, dif):\n",
    "        if dif['inside']:\n",
    "            self.sets[dif['dim']].remove(dif['entity'])\n",
    "        else:\n",
    "            self.sets[dif['dim']].add(dif['entity'])\n",
    "            \n",
    "    def try_update(self, dif):\n",
    "        sets = copy.deepcopy(self.sets)\n",
    "        if dif['inside']:\n",
    "            sets[dif['dim']].remove(dif['entity'])\n",
    "        else:\n",
    "            sets[dif['dim']].add(dif['entity'])\n",
    "        box_hash = self.get_hash(sets)\n",
    "        return box_hash\n",
    "    \n",
    "    def get_cur_hash(self):\n",
    "        return self.get_hash(self.sets)\n",
    "    \n",
    "    def get_hash(self, sets):\n",
    "        common_list = []\n",
    "        for cur_set in sets:\n",
    "            common_list.extend(sorted(cur_set))\n",
    "        box_hash = hash(tuple(common_list))\n",
    "        return box_hash\n",
    "\n",
    "class Clusterization:\n",
    "    \n",
    "    def get_clusters(self, data_matrix, euristic=0):\n",
    "        boxes = []\n",
    "        data_matrix_cur = copy.deepcopy(data_matrix)\n",
    "        not_used_idx = [i for i in range(0, data_matrix.shape[0])]\n",
    "        for i in range(data_matrix.shape[0]):\n",
    "            if euristic == 1:\n",
    "                if i not in not_used_idx:\n",
    "                    continue\n",
    "            cur_box = self.FourClusterBox(i, data_matrix_cur, not_used_idx)\n",
    "            new_box = True\n",
    "            for box_set in cur_box.sets:\n",
    "                if len(box_set) == 0:\n",
    "                    new_box = False\n",
    "            if new_box:\n",
    "                boxes.append(cur_box)\n",
    "                if euristic == 1:\n",
    "                    not_used_idx_upd = []\n",
    "                    for idx in not_used_idx:\n",
    "                        if idx not in cur_box.sets[0]:\n",
    "                            not_used_idx_upd.append(idx)\n",
    "                    not_used_idx = not_used_idx_upd\n",
    "        return boxes\n",
    "\n",
    "    def find_dif(self, box, dim, entity, inside):\n",
    "        def get_z(inside):\n",
    "            if inside:\n",
    "                return -1\n",
    "            return 1\n",
    "        \n",
    "        def get_cur_sets_sum(box):\n",
    "            idx = []\n",
    "            for box_set in box.sets:\n",
    "                idx.append(list(box_set))\n",
    "            return box.data_shift[np.ix_(*idx)].sum()\n",
    "        \n",
    "        def get_entity_sets_sum(box, dim, entity):\n",
    "            idx = []\n",
    "            for i, box_set in enumerate(box.sets):\n",
    "                if i == dim:\n",
    "                    idx.append([entity])\n",
    "                else:\n",
    "                    idx.append(list(box_set))\n",
    "            return box.data_shift[np.ix_(*idx)].sum()\n",
    "        \n",
    "        z = get_z(inside)\n",
    "        cur_sets_sum = get_cur_sets_sum(box)\n",
    "        entity_sets_sum = get_entity_sets_sum(box, dim, entity)\n",
    "        terms = []\n",
    "        terms.append(entity_sets_sum**2)\n",
    "        if box.dim == 2:\n",
    "            terms[0] = terms[0] * z\n",
    "        terms.append(2 * z * cur_sets_sum * entity_sets_sum)\n",
    "        terms.append(((-1) * cur_sets_sum **2)/len(box.sets[dim]))\n",
    "        if box.dim != 2:\n",
    "            terms[2] = terms[2] * z\n",
    "        numerator = np.array(terms).sum()\n",
    "        set_lengths = 1\n",
    "        for i in range(box.dim):\n",
    "            if i != dim:\n",
    "                set_lengths *= len(box.sets[i])\n",
    "        denominator = (len(box.sets[dim]) + z) * set_lengths\n",
    "        if denominator != 0:\n",
    "            dif = numerator/denominator\n",
    "        else:\n",
    "            dif = -np.inf\n",
    "        return dif\n",
    "\n",
    "    def FourClusterBox(self, initial_i, data_matrix, not_used_idx):\n",
    "        box = Box(data_matrix, initial_i)\n",
    "        ind = 0\n",
    "        start = time.time()\n",
    "        uniq_boxes = set()#avoid repeating boxes\n",
    "        uniq_boxes.add(box.get_cur_hash())\n",
    "        while(True):\n",
    "            ind += 1\n",
    "            max_dif = {'value': -np.inf, 'dim': -1, 'entity': -1, 'inside': -1}\n",
    "            for dim in range(box.dim):\n",
    "                for entity in range(box.data.shape[dim]):\n",
    "                    if dim == 0 and entity not in not_used_idx:\n",
    "                        continue\n",
    "                    inside = entity in box.sets[dim]\n",
    "                    if inside and len(box.sets[dim]) == 1:\n",
    "                        continue\n",
    "                    possible_dif = {'dim': dim, 'entity': entity, 'inside': inside}\n",
    "                    cur_hash = box.try_update(possible_dif)\n",
    "                    if cur_hash in uniq_boxes:#avoid box repeating\n",
    "                        continue \n",
    "                    cur_dif = self.find_dif(box, dim, entity, inside)\n",
    "                    if cur_dif > max_dif['value']:\n",
    "                        max_dif['value'] = cur_dif\n",
    "                        max_dif['dim'] = dim\n",
    "                        max_dif['entity'] = entity\n",
    "                        max_dif['inside'] = inside\n",
    "            if max_dif['value'] <= 0:\n",
    "                break\n",
    "            box.update(max_dif)\n",
    "            uniq_boxes.add(box.get_cur_hash())\n",
    "        return box\n",
    "\n",
    "class NonOverlappingCluster:\n",
    "    def __init__(self, data_matrix_size, clusters_num_borders={'min':4, 'max':5}):\n",
    "        initial_sets = self.generate_sets(data_matrix_size)\n",
    "        K = np.random.randint(clusters_num_borders['min'], clusters_num_borders['max'])\n",
    "        self.tricluster_sets = self.generate_triclusters(initial_sets, K)\n",
    "        self.data_matrix = self.generate_data_matrix(data_matrix_size)\n",
    "        \n",
    "    def generate_sets(self, size_sets):\n",
    "        sets = []\n",
    "        for size_set in size_sets:\n",
    "            cur_set = [i for i in range(size_set)]\n",
    "            sets.append(cur_set)\n",
    "        return sets\n",
    "    \n",
    "    def generate_triclusters(self, initial_sets, K):\n",
    "        tricluster_sets = []\n",
    "        for k in range(K):\n",
    "            tricluster_set = []\n",
    "            for initial_set in initial_sets:\n",
    "                max_tricluster_size = int(29/K)\n",
    "                tricluster_size = np.random.randint(4, max_tricluster_size - 1)\n",
    "                tricluster_elements = [initial_set.pop(random.randrange(len(initial_set))) for _ in range(tricluster_size)]\n",
    "                tricluster_set.append(tricluster_elements)\n",
    "            tricluster_sets.append(tricluster_set)\n",
    "        return tricluster_sets\n",
    "    \n",
    "    def generate_data_matrix(self, data_matrix_size):\n",
    "        data_matrix = np.zeros(data_matrix_size)\n",
    "        for tricluster_set in self.tricluster_sets:\n",
    "            elements = list(itertools.product(*tricluster_set))\n",
    "            for element in elements:\n",
    "                data_matrix[element] = 1\n",
    "        return data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 ms, sys: 1.75 ms, total: 3.83 ms\n",
      "Wall time: 2.13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "t=29\n",
    "data_matrix_size = [t, t+1, t+2, t+3]\n",
    "data = NonOverlappingCluster(data_matrix_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20856507230255839"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data_matrix.sum()/data.data_matrix.size * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.tricluster_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:117: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  1  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  2  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  3  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  4  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  5  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  6  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  7  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  8  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  9  mean : 1.0  std:  0.0 number of clusters 4\n",
      "CPU times: user 5.16 s, sys: 104 ms, total: 5.26 s\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_0 = make_experiment(0, data.data_matrix, data.tricluster_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 0.4953665614356404  std:  0.21190634933070474 number of clusters 5\n",
      "uniform_noise experiment  1  mean : 0.47659025297713214  std:  0.19826543935674099 number of clusters 6\n",
      "uniform_noise experiment  2  mean : 0.5976073087804623  std:  0.2646751977833349 number of clusters 7\n",
      "uniform_noise experiment  3  mean : 0.5549695662127727  std:  0.23967021445039996 number of clusters 8\n",
      "uniform_noise experiment  4  mean : 0.5024833058453414  std:  0.23217714493635 number of clusters 11\n",
      "uniform_noise experiment  5  mean : 0.5008378811590886  std:  0.2570309222191543 number of clusters 6\n",
      "uniform_noise experiment  6  mean : 0.6937389272243811  std:  0.2911280114819827 number of clusters 5\n",
      "uniform_noise experiment  7  mean : 0.5628584184256453  std:  0.31041305970278454 number of clusters 7\n",
      "uniform_noise experiment  8  mean : 0.5407640897114582  std:  0.26356624719014987 number of clusters 5\n",
      "uniform_noise experiment  9  mean : 0.5747959760060324  std:  0.2853817078200692 number of clusters 7\n",
      "CPU times: user 3min 36s, sys: 2.78 s, total: 3min 39s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_05 = make_experiment(0.05, data.data_matrix, data.tricluster_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 0.42927101434212506  std:  0.22249103697060704 number of clusters 10\n",
      "uniform_noise experiment  1  mean : 0.4930363650797087  std:  0.2806873657367821 number of clusters 10\n",
      "uniform_noise experiment  2  mean : 0.5425485926223377  std:  0.28052684443998643 number of clusters 8\n",
      "uniform_noise experiment  3  mean : 0.6139364956508918  std:  0.29792879153733204 number of clusters 6\n",
      "uniform_noise experiment  4  mean : 0.6049937042124541  std:  0.32474543957489765 number of clusters 6\n",
      "uniform_noise experiment  5  mean : 0.6320400085091246  std:  0.28937776277307914 number of clusters 6\n",
      "uniform_noise experiment  6  mean : 0.5264313850332325  std:  0.28016157863111973 number of clusters 9\n",
      "uniform_noise experiment  7  mean : 0.5515509652536791  std:  0.2880965432885452 number of clusters 8\n",
      "uniform_noise experiment  8  mean : 0.5128059904468447  std:  0.27485559151171324 number of clusters 10\n",
      "uniform_noise experiment  9  mean : 0.619215146887003  std:  0.31331298878552005 number of clusters 6\n",
      "CPU times: user 3min 39s, sys: 2.28 s, total: 3min 41s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_10 = make_experiment(0.1, data.data_matrix, data.tricluster_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 0.44990906298062766  std:  0.21811435853192251 number of clusters 13\n",
      "uniform_noise experiment  1  mean : 0.4723853506815968  std:  0.2338956669854041 number of clusters 15\n",
      "uniform_noise experiment  2  mean : 0.5365629825648208  std:  0.24706132030559932 number of clusters 8\n",
      "uniform_noise experiment  3  mean : 0.41552922338526055  std:  0.11471620062577458 number of clusters 15\n",
      "uniform_noise experiment  4  mean : 0.43028697679872746  std:  0.16296195681760586 number of clusters 11\n",
      "uniform_noise experiment  5  mean : 0.40156636946787866  std:  0.10654076736372776 number of clusters 15\n",
      "uniform_noise experiment  6  mean : 0.45827061209146236  std:  0.19717294423090675 number of clusters 13\n",
      "uniform_noise experiment  7  mean : 0.477775589505689  std:  0.23645098770924697 number of clusters 13\n",
      "uniform_noise experiment  8  mean : 0.5229103226943961  std:  0.3001557032106092 number of clusters 11\n",
      "uniform_noise experiment  9  mean : 0.4012117738328592  std:  0.09852883531639993 number of clusters 13\n",
      "CPU times: user 4min 31s, sys: 2.6 s, total: 4min 34s\n",
      "Wall time: 4min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_30 = make_experiment(0.3, data.data_matrix, data.tricluster_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('series1_matrix.npy', data.data_matrix)\n",
    "df_0.to_excel('series1_prob00.xlsx', index=False)\n",
    "df_05.to_excel('series1_prob05.xlsx', index=False)\n",
    "df_10.to_excel('series1_prob10.xlsx', index=False)\n",
    "df_30.to_excel('series1_prob30.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], slice(None, None, None), slice(None, None, None), slice(None, None, None)]\n",
      "[[1], slice(None, None, None), slice(None, None, None), slice(None, None, None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2], slice(None, None, None), slice(None, None, None), slice(None, None, None)]\n",
      "[[6], slice(None, None, None), slice(None, None, None), slice(None, None, None)]\n",
      "[{19, 12, 5}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}]\n",
      "aaaaaaa\n",
      "[{13, 14, 15, 16, 17, 18}, {9, 10, 11, 12, 13, 14, 15, 16, 17}, {5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}, {4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}]\n",
      "aaaaaaa\n",
      "[{0, 1, 2, 3, 4}, {8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}, {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}]\n",
      "aaaaaaa\n",
      "[{6, 7, 8, 9, 10, 11}, {3, 4, 5, 6, 7, 8, 9, 10, 11}, {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}, {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}]\n",
      "aaaaaaa\n",
      "uniform_noise experiment  0  mean : 0.8156249999999999  std:  0.18485108026462818 number of clusters 4\n"
     ]
    }
   ],
   "source": [
    "make_experiment(0.1, data_matrix, tetraclusters, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverlappingCluster:\n",
    "    def __init__(self, num_clusters, size=[29, 30, 31, 32]):\n",
    "        '''\n",
    "            create size matrix with clusters not overlapping by the first coordinate (wlog) and with minimum sparsity\n",
    "        '''\n",
    "        tetraclusters = [[[] for j in range(len(size))] for i in range(num_clusters)]\n",
    "        self.generate_non_overlapping(size[0], num_clusters, tetraclusters, 0)\n",
    "        for i in range(1, len(size)):\n",
    "            self.generate_overlapping(size[i], num_clusters, tetraclusters, i)\n",
    "        self.tetraclusters = tetraclusters\n",
    "        self.data_matrix = self.generate_data_matrix(size)\n",
    "    \n",
    "    def generate_non_overlapping(self, size, num_clusters, tetraclusters, dim):\n",
    "        cluster_size = int(size/num_clusters) - 1\n",
    "        initial_set = [i for i in range(size)]\n",
    "        for cur_cluster in range(num_clusters):\n",
    "            cluster_elements = [initial_set.pop(random.randrange(len(initial_set))) for _ in range(cluster_size)]\n",
    "            tetraclusters[cur_cluster][dim] = cluster_elements\n",
    "\n",
    "    def generate_overlapping(self, size, num_clusters, tetraclusters, dim):\n",
    "        initial_list = [i for i in range(size)]\n",
    "        for cur_cluster in range(num_clusters):\n",
    "            min_cluster_size = 2\n",
    "            max_cluster_size = int(size/2) - num_clusters\n",
    "            cluster_size = np.random.randint(min_cluster_size, max_cluster_size)\n",
    "            cluster_elements = random.sample(initial_list, cluster_size)\n",
    "            tetraclusters[cur_cluster][dim] = cluster_elements\n",
    "            \n",
    "    def generate_data_matrix(self, data_matrix_size):\n",
    "        data_matrix = np.zeros(data_matrix_size)\n",
    "        for tetracluster in self.tetraclusters:\n",
    "            elements = list(itertools.product(*tetracluster))\n",
    "            for element in elements:\n",
    "                data_matrix[element] = 1\n",
    "        return data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = OverlappingCluster(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[5, 18, 10, 19, 3, 4],\n",
       "  [0, 1, 6, 14, 13, 18, 2, 10, 17],\n",
       "  [3, 23, 0, 2, 9, 18, 25],\n",
       "  [10, 24, 6, 9, 4, 0, 17, 29]],\n",
       " [[21, 27, 11, 1, 22, 9],\n",
       "  [0, 10],\n",
       "  [17, 14, 23, 16, 11, 27, 30, 1, 13, 0],\n",
       "  [18, 26, 8, 27, 20, 14, 22]],\n",
       " [[25, 0, 20, 15, 16, 7],\n",
       "  [2, 29, 4, 26, 5, 10, 1, 22, 28],\n",
       "  [12, 27, 19, 22, 4, 0, 28, 7],\n",
       "  [27, 1, 14]],\n",
       " [[2, 12, 24, 13, 28, 6], [21, 26, 12], [6, 3], [21, 4, 13, 29, 0, 11, 9]]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.tetraclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster.tetraclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6270856507230256"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.data_matrix.sum()/cluster.data_matrix.size * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:117: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  1  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  2  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  3  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  4  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  5  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  6  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  7  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  8  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  9  mean : 1.0  std:  0.0 number of clusters 4\n",
      "CPU times: user 5.74 s, sys: 108 ms, total: 5.84 s\n",
      "Wall time: 5.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_0 = make_experiment(0, cluster.data_matrix, cluster.tetraclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 0.6752739731629674  std:  0.2313671891955107 number of clusters 3\n",
      "uniform_noise experiment  1  mean : 0.6032815380765131  std:  0.2319009733414801 number of clusters 4\n",
      "uniform_noise experiment  2  mean : 0.6622664835164834  std:  0.2821281969265921 number of clusters 5\n",
      "uniform_noise experiment  3  mean : 0.6974859775641026  std:  0.3041047005432564 number of clusters 4\n",
      "uniform_noise experiment  4  mean : 0.7176679867349238  std:  0.284769040819147 number of clusters 4\n",
      "uniform_noise experiment  5  mean : 0.7103473681139122  std:  0.24052388659316723 number of clusters 4\n",
      "uniform_noise experiment  6  mean : 0.8237165555877524  std:  0.24930243790964426 number of clusters 3\n",
      "uniform_noise experiment  7  mean : 0.6319078144078144  std:  0.21567796410959117 number of clusters 4\n",
      "uniform_noise experiment  8  mean : 0.8222201273671862  std:  0.2514187069942867 number of clusters 3\n",
      "uniform_noise experiment  9  mean : 0.6702297276337392  std:  0.2743404619937764 number of clusters 5\n",
      "CPU times: user 3min 9s, sys: 2.82 s, total: 3min 12s\n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_5 = make_experiment(0.05, cluster.data_matrix, cluster.tetraclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 0.7177886530518004  std:  0.24321753171422078 number of clusters 4\n",
      "uniform_noise experiment  1  mean : 0.5485028437348947  std:  0.2658686502978247 number of clusters 4\n",
      "uniform_noise experiment  2  mean : 0.6715741329426508  std:  0.2963359614816881 number of clusters 4\n",
      "uniform_noise experiment  3  mean : 0.7599023701079622  std:  0.21921169816847313 number of clusters 4\n",
      "uniform_noise experiment  4  mean : 0.6202336530759452  std:  0.312843766408164 number of clusters 5\n",
      "uniform_noise experiment  5  mean : 0.6039468667583993  std:  0.29274681384218376 number of clusters 5\n",
      "uniform_noise experiment  6  mean : 0.7467082289055973  std:  0.27793332582007535 number of clusters 5\n",
      "uniform_noise experiment  7  mean : 0.7262241872119969  std:  0.2632159727284131 number of clusters 5\n",
      "uniform_noise experiment  8  mean : 0.6699712975195683  std:  0.2734071987171584 number of clusters 5\n",
      "uniform_noise experiment  9  mean : 0.642106338836602  std:  0.26246367343256766 number of clusters 5\n",
      "CPU times: user 3min 34s, sys: 3.09 s, total: 3min 37s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_10 = make_experiment(0.1, cluster.data_matrix, cluster.tetraclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 0.5203932427927617  std:  0.30502896406238356 number of clusters 7\n",
      "uniform_noise experiment  1  mean : 0.48260228369554997  std:  0.2324629678197856 number of clusters 6\n",
      "uniform_noise experiment  2  mean : 0.5918264353841463  std:  0.29570596049627157 number of clusters 8\n",
      "uniform_noise experiment  3  mean : 0.7538438644688645  std:  0.29307802963977836 number of clusters 5\n",
      "uniform_noise experiment  4  mean : 0.52360702293738  std:  0.274917492643149 number of clusters 7\n",
      "uniform_noise experiment  5  mean : 0.6246898883504584  std:  0.29624297238134045 number of clusters 7\n",
      "uniform_noise experiment  6  mean : 0.44291461724281483  std:  0.21304325787158543 number of clusters 8\n",
      "uniform_noise experiment  7  mean : 0.5076516643305858  std:  0.26032282708420895 number of clusters 9\n",
      "uniform_noise experiment  8  mean : 0.6740578885539722  std:  0.29262568479930534 number of clusters 6\n",
      "uniform_noise experiment  9  mean : 0.6643564205653022  std:  0.3106197361218272 number of clusters 6\n",
      "CPU times: user 3min 55s, sys: 2.94 s, total: 3min 58s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_30 = make_experiment(0.3, cluster.data_matrix, cluster.tetraclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('series2_matrix.npy', cluster.data_matrix)\n",
    "df_0.to_excel('series2_prob00.xlsx', index=False)\n",
    "df_5.to_excel('series2_prob05.xlsx', index=False)\n",
    "df_10.to_excel('series2_prob10.xlsx', index=False)\n",
    "df_30.to_excel('series2_prob30.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.stats import hmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data_matrix, distribution, prob):\n",
    "    if distribution == 'uniform':# prob = probablitiy to change value in datamatrix\n",
    "        np.random.seed(random.randint(1, 1e9))\n",
    "        noise = np.random.uniform(0, 1, data_matrix.shape)\n",
    "        data_matrix[(noise <= prob) & (data_matrix == 1)] = 0\n",
    "        data_matrix[(noise <= prob) & (data_matrix == 0)] = 1\n",
    "    if distribution == 'normal':# prob = deviation in normal distribution\n",
    "        noise = np.random.normal(0, prob, data_matrix.shape)\n",
    "        data_matrix = data_matrix + noise\n",
    "    return data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxResult:\n",
    "    def __init__(self, cluster_predict):\n",
    "        self.score = -np.inf\n",
    "        self.predict = cluster_predict\n",
    "        self.test = np.nan\n",
    "        self.test_id = -np.inf\n",
    "        \n",
    "    def update(self, cluster_test, cluster_test_id):\n",
    "        #cur_score = self.jaccard(cluster_test)\n",
    "        cur_score = self.kluch(cluster_test)\n",
    "        if cur_score > self.score:\n",
    "            self.score = cur_score\n",
    "            self.test = cluster_test\n",
    "            self.test_id = cluster_test_id\n",
    "    \n",
    "    def jaccard(self, cluster_test):\n",
    "        dimension_score = []\n",
    "        for dim in range(len(self.predict)):\n",
    "            s1 = self.predict[dim]\n",
    "            s2 = set(cluster_test[dim])\n",
    "            dim_score = float(len(s1.intersection(s2)) / len(s1.union(s2)))\n",
    "            dimension_score.append(dim_score)\n",
    "        score = np.mean(dimension_score)\n",
    "        return score\n",
    "    \n",
    "    def kluch(self, cluster_test):\n",
    "        dimension_score = []\n",
    "        for dim in range(len(self.predict)):\n",
    "            s1 = self.predict[dim]\n",
    "            s2 = set(cluster_test[dim])\n",
    "            intersect = len(s1.intersection(s2))\n",
    "            dim_score = (float(intersect / len(s1)) + float(intersect / len(s2)))/2\n",
    "            dimension_score.append(dim_score)\n",
    "        score = np.mean(dimension_score)\n",
    "        return score\n",
    "    \n",
    "def check_similarity_2(clusters_test, clusters_predict):#находим для каждого изначального кластера макимально похожий на него\n",
    "    box_results = []\n",
    "    for i, cluster_test in enumerate(clusters_test):\n",
    "        for cluster_predict in clusters_predict:\n",
    "            box_result = BoxResult(cluster_predict.sets)\n",
    "            box_result.update(cluster_test, i)\n",
    "        box_results.append(box_result)\n",
    "    return box_results\n",
    "        \n",
    "def check_similarity(clusters_test, clusters_predict):\n",
    "    box_results = []\n",
    "    for cluster_predict in clusters_predict:\n",
    "        box_result = BoxResult(cluster_predict.sets)\n",
    "        for i, cluster_test in enumerate(clusters_test):\n",
    "            box_result.update(cluster_test, i)\n",
    "        box_results.append(box_result)\n",
    "    return box_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size = {\n",
    "    0: {1:[1, 4], 2:[6, 10], 3:[12, 16], 4:[17, 20]},\n",
    "    1: {1:[1, 6], 2:[3, 9], 3:[6, 12], 4:[10, 16]},\n",
    "    2: {1:[1, 9], 2:[3, 12], 3:[6, 11], 4:[10, 15]},\n",
    "    3: {1:[2, 10], 2:[4, 12], 3:[7, 12], 4:[12, 17]}\n",
    "}# 4 clusters\n",
    "dim_size_3 = {\n",
    "    0: {1:[1, 5], 2:[7, 12], 3:[14, 19]},\n",
    "    1: {1:[1, 8], 2:[4, 12], 3:[10, 18]},\n",
    "    2: {1:[1, 11], 2:[3, 14], 3:[6, 18]},\n",
    "    3: {1:[2, 14], 2:[3, 16], 3:[5, 20]}\n",
    "}#3 clusters\n",
    "matrix_size = [20, 20, 20, 20]\n",
    "def create_fixed_data_matrix(matrix_size, dim_size, num_clusters):\n",
    "    tetraclusters = [[[] for j in range(0, 4)] for i in range(0, num_clusters)]\n",
    "    for i in range(4): #all dims\n",
    "        for j in range(1, num_clusters+1):#all clusters\n",
    "            for u in range(dim_size[i][j][0], dim_size[i][j][1] + 1):\n",
    "                tetraclusters[j-1][i].append(u-1)\n",
    "    data_matrix = np.zeros(matrix_size)\n",
    "    for tetracluster in tetraclusters:\n",
    "        elements = list(itertools.product(*tetracluster))\n",
    "        for element in elements:\n",
    "            data_matrix[element] = 1\n",
    "    return data_matrix, tetraclusters\n",
    "data_matrix, tetraclusters = create_fixed_data_matrix(matrix_size, dim_size, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_experiment(prob, data_matrix, tetraclusters):\n",
    "    number_exeperiments = 10\n",
    "    data_matrix_uniform_noise_prev = 0\n",
    "    df = pd.DataFrame(columns=['number_experiment', 'mean', 'std','number of clusters'])\n",
    "    for i in range(number_exeperiments):\n",
    "        start_time = time.time()\n",
    "        data_matrix_uniform_noise = add_noise(copy.deepcopy(data_matrix), 'uniform', prob)\n",
    "        clusters_uniform_noise = Clusterization().get_clusters(data_matrix_uniform_noise, 1)\n",
    "        uniform_noise_results = check_similarity(tetraclusters, clusters_uniform_noise)\n",
    "        uniform_noise_results = np.array([uniform_noise_result.score for uniform_noise_result in uniform_noise_results])\n",
    "        data_matrix_uniform_noise_prev = data_matrix_uniform_noise\n",
    "        df.loc[i, :] = [i+1, uniform_noise_results.mean(), uniform_noise_results.std(), uniform_noise_results.shape[0]]\n",
    "        print('uniform_noise experiment ', i,  ' mean :', uniform_noise_results.mean(), ' std: ', uniform_noise_results.std(), \n",
    "             'number of clusters', uniform_noise_results.shape[0])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.601249999999999"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.sum()/data_matrix.size * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:117: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  1  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  2  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  3  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  4  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  5  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  6  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  7  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  8  mean : 1.0  std:  0.0 number of clusters 4\n",
      "uniform_noise experiment  9  mean : 1.0  std:  0.0 number of clusters 4\n",
      "CPU times: user 2.86 s, sys: 61.1 ms, total: 2.92 s\n",
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_0 = make_experiment(0, data_matrix, tetraclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 0.7657986111111111  std:  0.2342385791244292 number of clusters 4\n",
      "uniform_noise experiment  1  mean : 0.736498538011696  std:  0.21630766988131814 number of clusters 5\n",
      "uniform_noise experiment  2  mean : 0.7657986111111111  std:  0.2342385791244292 number of clusters 4\n",
      "uniform_noise experiment  3  mean : 0.762375992063492  std:  0.23779492236412222 number of clusters 4\n",
      "uniform_noise experiment  4  mean : 0.74  std:  0.2128893491934249 number of clusters 5\n",
      "uniform_noise experiment  5  mean : 0.7690876831501832  std:  0.23091281067270836 number of clusters 4\n",
      "uniform_noise experiment  6  mean : 0.74  std:  0.2128893491934249 number of clusters 5\n",
      "uniform_noise experiment  7  mean : 0.74  std:  0.2128893491934249 number of clusters 5\n",
      "uniform_noise experiment  8  mean : 0.7657986111111111  std:  0.2342385791244292 number of clusters 4\n",
      "uniform_noise experiment  9  mean : 0.7816964285714285  std:  0.21866844325137447 number of clusters 4\n",
      "CPU times: user 27.8 s, sys: 444 ms, total: 28.2 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_05 = make_experiment(0.05, data_matrix, tetraclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 0.8434095860566448  std:  0.22145228713630982 number of clusters 3\n",
      "uniform_noise experiment  1  mean : 0.7690876831501832  std:  0.23091281067270836 number of clusters 4\n",
      "uniform_noise experiment  2  mean : 0.7631983604845447  std:  0.23702023572380262 number of clusters 4\n",
      "uniform_noise experiment  3  mean : 0.7822720864661654  std:  0.21814239634206142 number of clusters 4\n",
      "uniform_noise experiment  4  mean : 0.7855769230769232  std:  0.21454188886649236 number of clusters 4\n",
      "uniform_noise experiment  5  mean : 0.740657894736842  std:  0.21226671649959164 number of clusters 5\n",
      "uniform_noise experiment  6  mean : 0.762797619047619  std:  0.2377843021779295 number of clusters 4\n",
      "uniform_noise experiment  7  mean : 0.7657986111111111  std:  0.2342385791244292 number of clusters 4\n",
      "uniform_noise experiment  8  mean : 0.7801339285714286  std:  0.22011271517569198 number of clusters 4\n",
      "uniform_noise experiment  9  mean : 0.7830827067669173  std:  0.21725239792187986 number of clusters 4\n",
      "CPU times: user 30.1 s, sys: 527 ms, total: 30.6 s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_10 = make_experiment(0.1, data_matrix, tetraclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 0.770704334365325  std:  0.2298784221614642 number of clusters 4\n",
      "uniform_noise experiment  1  mean : 0.8272546897546897  std:  0.24429876058526567 number of clusters 3\n",
      "uniform_noise experiment  2  mean : 0.8419241433947316  std:  0.22355302029491514 number of clusters 3\n",
      "uniform_noise experiment  3  mean : 0.6623309566895093  std:  0.2783325143664657 number of clusters 5\n",
      "uniform_noise experiment  4  mean : 0.7349358974358975  std:  0.2659188463427079 number of clusters 4\n",
      "uniform_noise experiment  5  mean : 0.7475816462948816  std:  0.2524206899046249 number of clusters 4\n",
      "uniform_noise experiment  6  mean : 0.7833508403361344  std:  0.21697808306763344 number of clusters 4\n",
      "uniform_noise experiment  7  mean : 0.832033326687932  std:  0.2375407474246176 number of clusters 3\n",
      "uniform_noise experiment  8  mean : 0.7689764776524646  std:  0.23119463345143573 number of clusters 4\n",
      "uniform_noise experiment  9  mean : 0.7592209690893902  std:  0.24141632535882113 number of clusters 4\n",
      "CPU times: user 31.5 s, sys: 497 ms, total: 32 s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_30 = make_experiment(0.3, data_matrix, tetraclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denissurin/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_noise experiment  0  mean : 0.6073186733901019  std:  0.24934906396058543 number of clusters 7\n",
      "uniform_noise experiment  1  mean : 0.6781638071895425  std:  0.26770879077412707 number of clusters 5\n",
      "uniform_noise experiment  2  mean : 0.7512310172466422  std:  0.24935265176581123 number of clusters 4\n",
      "uniform_noise experiment  3  mean : 0.8361365758424583  std:  0.23173787682049068 number of clusters 3\n",
      "uniform_noise experiment  4  mean : 0.8401829481792717  std:  0.22594978245535333 number of clusters 4\n",
      "uniform_noise experiment  5  mean : 0.6691849816849818  std:  0.2617142921003691 number of clusters 7\n",
      "uniform_noise experiment  6  mean : 0.7164314273689274  std:  0.2622974415826793 number of clusters 6\n",
      "uniform_noise experiment  7  mean : 0.5773003082351822  std:  0.2679557692967851 number of clusters 7\n",
      "uniform_noise experiment  8  mean : 0.6474465859576154  std:  0.25987111038901783 number of clusters 6\n",
      "uniform_noise experiment  9  mean : 0.847806686777275  std:  0.21523384766207415 number of clusters 3\n",
      "CPU times: user 33.7 s, sys: 335 ms, total: 34.1 s\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_60 = make_experiment(0.5, data_matrix, tetraclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('series3_matrix.npy', data_matrix)\n",
    "df_0.to_excel('series3_prob00.xlsx', index=False)\n",
    "df_5.to_excel('series3_prob05.xlsx', index=False)\n",
    "df_10.to_excel('series3_prob10.xlsx', index=False)\n",
    "df_30.to_excel('series3_prob30.xlsx', index=False)\n",
    "df_60.to_excel('series3_prob50.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
